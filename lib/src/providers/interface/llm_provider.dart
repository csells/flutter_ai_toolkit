// Copyright 2024 The Flutter Authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

import 'attachments.dart';
import 'chat_message.dart';

/// An abstract class representing a Language Model (LLM) provider.
///
/// This class defines the interface for interacting with different LLM
/// services. Implementations of this class should provide the logic for
/// generating text responses based on input prompts and optional attachments.
abstract class LlmProvider {
  /// Generates an embedding for a given document.
  ///
  /// This method should be implemented to create a numerical representation
  /// (embedding) of the input document, which can be used for tasks like
  /// semantic search or document comparison.
  ///
  /// [document] is the text content of the document to be embedded.
  ///
  /// Returns a [Future] that resolves to a [`List<double>`] representing the
  /// document's embedding.
  Future<List<double>> getDocumentEmbedding(String document);

  /// Generates an embedding for a given query.
  ///
  /// This method should be implemented to create a numerical representation
  /// (embedding) of the input query, which can be used for tasks like
  /// semantic search or query-document matching.
  ///
  /// [query] is the text content of the query to be embedded.
  ///
  /// Returns a [Future] that resolves to a [`List<double>`] representing the
  /// query's embedding.
  Future<List<double>> getQueryEmbedding(String query);

  /// Generates a stream of text based on the given prompt and attachments.
  /// This method does not interact with a chat or build on any chat history.
  ///
  /// [prompt] is the input text to generate a response for.
  /// [attachments] is an optional iterable of [Attachment] objects to include
  /// with the prompt. These can be images, files, or links that provide
  /// additional context for the LLM.
  ///
  /// Returns a [Stream] of [String] containing the generated text chunks. This
  /// allows for streaming responses as they are generated by the LLM.
  Stream<String> generateStream(
    String prompt, {
    Iterable<Attachment> attachments,
  });

  /// Generates a stream of text based on the given prompt and attachments.
  /// Interacts with a chat and builds on the history of the chat associated
  /// with the provider.
  ///
  /// This method should be implemented to interact with the specific LLM
  /// service and generate text responses.
  ///
  /// [prompt] is the input text to generate a response for. [attachments] is an
  /// optional iterable of [Attachment] objects to include with the prompt.
  /// These can be images, files, or links that provide additional context for
  /// the LLM.
  ///
  /// Returns a [Stream] of [String] containing the generated text chunks. This
  /// allows for streaming responses as they are generated by the LLM.
  Stream<String> sendMessageStream(
    String prompt, {
    Iterable<Attachment> attachments,
  });

  /// Returns an iterable of [ChatMessage] objects representing the chat
  /// history.
  ///
  /// This getter provides access to the conversation history maintained by the
  /// LLM provider. The history typically includes both user messages and LLM
  /// responses in chronological order.
  ///
  /// Returns an [Iterable] of [ChatMessage] objects.
  Iterable<ChatMessage> get history;

  /// Sets the chat history to the provided messages.
  ///
  /// This setter allows updating the conversation history maintained by the LLM
  /// provider. The provided [history] replaces the existing history with a new
  /// set of messages.
  ///
  /// [history] is an [Iterable] of [ChatMessage] objects representing the new
  /// chat history.
  set history(Iterable<ChatMessage> history);
}

/// A function that generates a stream of text based on a prompt and
/// attachments.
typedef LlmStreamGenerator = Stream<String> Function(
  String prompt, {
  required Iterable<Attachment> attachments,
});
